experiment: baseline_lr_0.00005
# resume: /mnt/data/Projects/centernet-uda/outputs/entropy_minimization/model_last.pth
model:
  uda:

datasets:
  training:
    params:
      target_domain_glob:
  validation:
    params:
      input_size: [800, 800]
      target_domain_glob:

optimizer:
  name: Adam
  params:
    lr: 0.00005
    weight_decay: 0.0001
    # momentum: 0.9
  scheduler:
    name: MultiStepLR
    params:
      milestones: [30, 60]
      gamma: 0.1
num_workers: 4
