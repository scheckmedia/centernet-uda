experiment: baseline_resnet_50_lr_0.00005
pretrained:
model:
  backend:
    name: resnet
    params:
      num_layers: 50
      num_classes: 6
  uda:

datasets:
  training:
    params:
      target_domain_glob:
  validation:
    params:
      input_size: [800, 800]
      target_domain_glob:

optimizer:
  name: Adam
  params:
    lr: 0.00005
    weight_decay: 0.0001
    # momentum: 0.9
  scheduler:
    name: MultiStepLR
    params:
      milestones: [30, 60]
      gamma: 0.1
num_workers: 6
batch_size: 8
